{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ---- Mount Drive and set up folders\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os\n",
        "PROJ = \"/content/drive/MyDrive/dissertation\"\n",
        "os.makedirs(f\"{PROJ}/data\", exist_ok=True)\n",
        "os.makedirs(f\"{PROJ}/outputs\", exist_ok=True)\n",
        "\n",
        "print(\" Drive mounted and folders ready!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaWixCMehE-Z",
        "outputId": "0da320b1-7fec-42db-964b-e2bdf03b457a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            " Drive mounted and folders ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Load config file\n",
        "import json\n",
        "\n",
        "CONFIG_PATH = \"/content/drive/MyDrive/dissertation/config.json\"\n",
        "\n",
        "with open(CONFIG_PATH) as f:\n",
        "    cfg = json.load(f)\n",
        "\n",
        "print(\" Config loaded successfully!\")\n",
        "print(json.dumps(cfg, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_9qff6whGVP",
        "outputId": "80ec3755-baee-4da9-cc5c-e3756e5fb485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Config loaded successfully!\n",
            "{\n",
            "  \"datasets\": {\n",
            "    \"adult\": {\n",
            "      \"path\": \"data/Adult_clean.csv\",\n",
            "      \"target\": \"income\",\n",
            "      \"embed_candidates\": [\n",
            "        \"occupation\",\n",
            "        \"workclass\",\n",
            "        \"native_country\"\n",
            "      ]\n",
            "    },\n",
            "    \"petfinder\": {\n",
            "      \"path\": \"data/Petfinder_clean.csv\",\n",
            "      \"target\": \"AdoptionSpeed_bin\",\n",
            "      \"embed_candidates\": [\n",
            "        \"Breed1\",\n",
            "        \"Color1\",\n",
            "        \"MaturitySize\"\n",
            "      ]\n",
            "    },\n",
            "    \"breast\": {\n",
            "      \"path\": \"data/Breast_clean.csv\",\n",
            "      \"target\": \"OS5yr_bin\",\n",
            "      \"embed_candidates\": [\n",
            "        \"TNM_PATH_T\",\n",
            "        \"TNM_PATH_N\",\n",
            "        \"TUMOR_SIZE\"\n",
            "      ]\n",
            "    }\n",
            "  },\n",
            "  \"splits\": {\n",
            "    \"test_size\": 0.2,\n",
            "    \"val_size\": 0.2,\n",
            "    \"random_state\": 42,\n",
            "    \"stratify\": true\n",
            "  }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Load datasets + split function\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_dataset(key):\n",
        "    meta = cfg[\"datasets\"][key]\n",
        "    path = \"/content/drive/MyDrive/dissertation/\" + meta[\"path\"]\n",
        "    df = pd.read_csv(path, low_memory=False)\n",
        "    y = df[meta[\"target\"]]\n",
        "    X = df.drop(columns=[meta[\"target\"]])\n",
        "    print(f\"Loaded {key}: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "    return X, y, meta\n",
        "\n",
        "def make_splits(X, y, cfg):\n",
        "    strat = y if cfg[\"splits\"][\"stratify\"] else None\n",
        "    X_tr, X_tmp, y_tr, y_tmp = train_test_split(\n",
        "        X, y, test_size=cfg[\"splits\"][\"val_size\"] + cfg[\"splits\"][\"test_size\"],\n",
        "        random_state=cfg[\"splits\"][\"random_state\"], stratify=strat)\n",
        "    rel = cfg[\"splits\"][\"test_size\"] / (cfg[\"splits\"][\"val_size\"] + cfg[\"splits\"][\"test_size\"])\n",
        "    X_val, X_te, y_val, y_te = train_test_split(\n",
        "        X_tmp, y_tmp, test_size=rel, random_state=cfg[\"splits\"][\"random_state\"],\n",
        "        stratify=(y_tmp if strat is not None else None))\n",
        "    return (X_tr, y_tr), (X_val, y_val), (X_te, y_te)\n"
      ],
      "metadata": {
        "id": "jk2ei-pzhH2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f\"{PROJ}/outputs/breast_cleaning_notes.txt\", \"a\") as f:\n",
        "    f.write(\"\\n\\n[2025-11-04] Updated embedding features: TNM_PATH_T, TNM_PATH_N, hospid (replaces tumor_size).\")\n"
      ],
      "metadata": {
        "id": "pjlZrWTxdl3k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}